{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da328fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import gradio as gr \n",
    "import pandas as pd\n",
    "import chromadb\n",
    "import uuid\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "import re\n",
    "from urllib.parse import urljoin, urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401313af",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key=\"\",\n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://86ddea520403cf6d08.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://86ddea520403cf6d08.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class JobAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.client = chromadb.PersistentClient('vectorstore')\n",
    "        self.collections = self.client.get_or_create_collection(name=\"portfolio_app\")\n",
    "        self.api_key = \"\"\n",
    "\n",
    "    def load_portfolio(self, portfolio_csv):\n",
    "        \"\"\"Load portfolio data into vector database\"\"\"\n",
    "        df = pd.read_csv(portfolio_csv)\n",
    "\n",
    "        if not self.collections.count():\n",
    "            for i, row in df.iterrows():\n",
    "                self.collections.add(\n",
    "                    documents=[row['Technology']],\n",
    "                    ids=[str(uuid.uuid4())]\n",
    "                )\n",
    "        return df\n",
    "\n",
    "    def extract_job_posting(self, url):\n",
    "        \"\"\"Extract job posting information from URL\"\"\"\n",
    "        loader = WebBaseLoader(url)\n",
    "        page_data = loader.load().pop().page_content\n",
    "\n",
    "        prompt_extract = PromptTemplate.from_template(\"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the\n",
    "        following keys: `role`, `experience`, `skills`, `description`, `company`, `location`, `requirements`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):\n",
    "        \"\"\")\n",
    "\n",
    "        chain_extract = prompt_extract | llm\n",
    "        res = chain_extract.invoke(input={'page_data': page_data})\n",
    "        json_parser = JsonOutputParser()\n",
    "        return json_parser.parse(res.content)\n",
    "\n",
    "    def analyze_skills_and_generate_questions(self, job_description):\n",
    "        \"\"\"Analyze skills match and generate interview questions\"\"\"\n",
    "        prompt_skills_and_question = PromptTemplate.from_template(\"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "\n",
    "        ### INSTRUCTION:\n",
    "        You are Mishu Dhar Chando, the CEO of Knowledge Doctor, a YouTube channel specializing in educating individuals on machine learning, deep learning, and natural language processing.\n",
    "        Your expertise lies in bridging the gap between theoretical knowledge and practical applications through engaging content and innovative problem-solving techniques.\n",
    "        Your job is to:\n",
    "        1. Analyze the given job description to identify the required technical skills and match them with the provided skill set to calculate a percentage match.\n",
    "        2. Generate a list of relevant interview questions based on the job description.\n",
    "        3. Return the information in JSON format with the following keys:\n",
    "            - `skills_match`: A dictionary where each key is a skill, and the value is the matching percentage.\n",
    "            - `interview_questions`: A list of tailored questions related to the job description.\n",
    "\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):\n",
    "        \"\"\")\n",
    "\n",
    "        chain_skills_and_question = prompt_skills_and_question | llm\n",
    "        res = chain_skills_and_question.invoke({\"job_description\": str(job_description)})\n",
    "        json_parser = JsonOutputParser()\n",
    "        return json_parser.parse(res.content)\n",
    "\n",
    "    def tailor_portfolio(self, portfolio_df, job_data):\n",
    "        \"\"\"NEW FEATURE 1: Tailor portfolio based on job requirements\"\"\"\n",
    "        prompt_tailor = PromptTemplate.from_template(\"\"\"\n",
    "        ### CURRENT PORTFOLIO:\n",
    "        {current_portfolio}\n",
    "        \n",
    "        ### JOB REQUIREMENTS:\n",
    "        {job_requirements}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are a career advisor helping tailor a portfolio for a specific job application.\n",
    "        Analyze the job requirements and current portfolio to suggest improvements.\n",
    "        \n",
    "        Return a JSON with:\n",
    "        - `missing_skills`: List of skills mentioned in job requirements but missing from portfolio\n",
    "        - `skill_gaps`: Skills that exist but need strengthening  \n",
    "        - `portfolio_suggestions`: Specific recommendations to improve portfolio alignment\n",
    "        - `new_portfolio_entries`: Suggested new entries to add to portfolio CSV\n",
    "        - `emphasis_areas`: Existing skills that should be highlighted more\n",
    "        \n",
    "        ### VALID JSON (NO PREAMBLE):\n",
    "        \"\"\")\n",
    "\n",
    "        current_portfolio = portfolio_df.to_string()\n",
    "        job_requirements = f\"Role: {job_data.get('role', '')}\\nSkills: {job_data.get('skills', '')}\\nRequirements: {job_data.get('requirements', '')}\"\n",
    "\n",
    "        chain_tailor = prompt_tailor | llm\n",
    "        res = chain_tailor.invoke({\n",
    "            \"current_portfolio\": current_portfolio,\n",
    "            \"job_requirements\": job_requirements\n",
    "        })\n",
    "        json_parser = JsonOutputParser()\n",
    "        return json_parser.parse(res.content)\n",
    "\n",
    "    def generate_cover_letter(self, portfolio_df, job_data):\n",
    "        \"\"\"NEW FEATURE 2: Generate personalized cover letter\"\"\"\n",
    "        prompt_cover_letter = PromptTemplate.from_template(\"\"\"\n",
    "        ### PORTFOLIO SKILLS:\n",
    "        {portfolio_skills}\n",
    "        \n",
    "        ### JOB DETAILS:\n",
    "        {job_details}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are a professional career coach. Generate a compelling cover letter that:\n",
    "        1. Addresses the specific company and role\n",
    "        2. Highlights relevant skills from the portfolio that match job requirements\n",
    "        3. Shows enthusiasm and cultural fit\n",
    "        4. Includes specific examples from the portfolio\n",
    "        5. Has a professional yet engaging tone\n",
    "        6. Is concise (3-4 paragraphs)\n",
    "        \n",
    "        Return a JSON with:\n",
    "        - `cover_letter`: The complete cover letter text\n",
    "        - `key_highlights`: List of portfolio items that were emphasized\n",
    "        - `customization_notes`: Suggestions for further personalization\n",
    "        \n",
    "        ### VALID JSON (NO PREAMBLE):\n",
    "        \"\"\")\n",
    "\n",
    "        portfolio_skills = portfolio_df['Technology'].tolist()\n",
    "        job_details = f\"\"\"\n",
    "        Company: {job_data.get('company', 'the company')}\n",
    "        Role: {job_data.get('role', '')}\n",
    "        Location: {job_data.get('location', '')}\n",
    "        Skills Required: {job_data.get('skills', '')}\n",
    "        Description: {job_data.get('description', '')}\n",
    "        \"\"\"\n",
    "\n",
    "        chain_cover_letter = prompt_cover_letter | llm\n",
    "        res = chain_cover_letter.invoke({\n",
    "            \"portfolio_skills\": portfolio_skills,\n",
    "            \"job_details\": job_details\n",
    "        })\n",
    "        json_parser = JsonOutputParser()\n",
    "        return json_parser.parse(res.content)\n",
    "\n",
    "    def find_matching_jobs(self, portfolio_df, search_terms=None, location=\"\", num_results=10):\n",
    "        \"\"\"NEW FEATURE 3: Job search agent based on portfolio\"\"\"\n",
    "        portfolio_skills = portfolio_df['Technology'].tolist()\n",
    "\n",
    "        # Generate search terms from portfolio if not provided\n",
    "        if not search_terms:\n",
    "            prompt_search_terms = PromptTemplate.from_template(\"\"\"\n",
    "            ### PORTFOLIO SKILLS:\n",
    "            {skills}\n",
    "            \n",
    "            ### INSTRUCTION:\n",
    "            Based on these skills, generate relevant job search terms and keywords.\n",
    "            Return a JSON with:\n",
    "            - `job_titles`: List of relevant job titles to search for\n",
    "            - `key_technologies`: Most important technologies from the portfolio\n",
    "            - `search_queries`: Optimized search queries for job boards\n",
    "            \n",
    "            ### VALID JSON (NO PREAMBLE):\n",
    "            \"\"\")\n",
    "\n",
    "            chain_search = prompt_search_terms | llm\n",
    "            res = chain_search.invoke({\"skills\": portfolio_skills})\n",
    "            json_parser = JsonOutputParser()\n",
    "            search_data = json_parser.parse(res.content)\n",
    "            search_terms = search_data.get('job_titles', ['Software Engineer', 'Developer'])\n",
    "\n",
    "        # Fetch jobs\n",
    "        jobs_found = self._simulate_job_search(search_terms, location, num_results)\n",
    "\n",
    "        # Rank jobs based on portfolio match\n",
    "        ranked_jobs = self._rank_jobs_by_portfolio_match(jobs_found, portfolio_skills)\n",
    "\n",
    "        return {\n",
    "            \"search_terms_used\": search_terms,\n",
    "            \"total_jobs_found\": len(jobs_found),\n",
    "            \"top_matches\": ranked_jobs[:5],  # ✅ includes URLs already\n",
    "            \"job_recommendations\": self._generate_job_recommendations(ranked_jobs, portfolio_skills)\n",
    "        }\n",
    "\n",
    "    def _simulate_job_search(self, search_terms, location, num_results=5):\n",
    "        \"\"\"Fetch job search results using a real API instead of mock data\"\"\"\n",
    "\n",
    "        url = \"https://jsearch.p.rapidapi.com/search\"\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Key\": self.api_key,\n",
    "            \"X-RapidAPI-Host\": \"jsearch.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "        query = {\n",
    "            \"query\": f\"{search_terms} in {location}\",\n",
    "            \"page\": 1,\n",
    "            \"num_pages\": 1\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=query)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                jobs = data.get(\"data\", [])\n",
    "\n",
    "                formatted_jobs = [\n",
    "                    {\n",
    "                        \"title\": job.get(\"job_title\"),\n",
    "                        \"company\": job.get(\"employer_name\"),\n",
    "                        \"location\": job.get(\"job_city\"),\n",
    "                        \"description\": job.get(\"job_description\"),\n",
    "                        \"skills_required\": job.get(\"job_required_skills\", []),\n",
    "                        \"url\": job.get(\"job_apply_link\"),  # ✅ Job link included\n",
    "                        \"salary_range\": (\n",
    "                            f\"{job.get('job_salary_currency', '')} \"\n",
    "                            f\"{job.get('job_min_salary', '')} - {job.get('job_max_salary', '')}\"\n",
    "                            if job.get(\"job_min_salary\") else \"Not specified\"\n",
    "                        )\n",
    "                    }\n",
    "                    for job in jobs[:num_results]\n",
    "                ]\n",
    "\n",
    "                return formatted_jobs\n",
    "            else:\n",
    "                return [{\"error\": f\"API request failed with status {response.status_code}\"}]\n",
    "\n",
    "        except Exception as e:\n",
    "            return [{\"error\": str(e)}]\n",
    "\n",
    "    def _rank_jobs_by_portfolio_match(self, jobs, portfolio_skills):\n",
    "        \"\"\"Rank jobs by how well they match portfolio skills\"\"\"\n",
    "        portfolio_skills_flat = []\n",
    "        for skill_set in portfolio_skills:\n",
    "            portfolio_skills_flat.extend([s.strip() for s in skill_set.split(',')])\n",
    "\n",
    "        for job in jobs:\n",
    "            job_skills = job.get('skills_required', [])\n",
    "            matches = sum(\n",
    "                1 for skill in job_skills if any(ps.lower() in skill.lower() or skill.lower() in ps.lower() for ps in portfolio_skills_flat)\n",
    "            )\n",
    "            job['match_score'] = (matches / len(job_skills)) * 100 if job_skills else 0\n",
    "            job['matching_skills'] = [\n",
    "                skill for skill in job_skills if any(ps.lower() in skill.lower() or skill.lower() in ps.lower() for ps in portfolio_skills_flat)\n",
    "            ]\n",
    "\n",
    "        return sorted(jobs, key=lambda x: x['match_score'], reverse=True)\n",
    "\n",
    "    def _generate_job_recommendations(self, ranked_jobs, portfolio_skills):\n",
    "        \"\"\"Generate personalized job recommendations\"\"\"\n",
    "        prompt_recommendations = PromptTemplate.from_template(\"\"\"\n",
    "        ### TOP MATCHING JOBS:\n",
    "        {top_jobs}\n",
    "        \n",
    "        ### PORTFOLIO SKILLS:\n",
    "        {portfolio_skills}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        Based on the job matches and portfolio skills, provide strategic recommendations:\n",
    "        \n",
    "        Return JSON with:\n",
    "        - `application_strategy`: How to approach these job applications\n",
    "        - `skill_development`: Skills to develop for better matches\n",
    "        - `networking_suggestions`: How to leverage connections\n",
    "        - `timeline_recommendations`: Suggested application timeline\n",
    "        \n",
    "        ### VALID JSON (NO PREAMBLE):\n",
    "        \"\"\")\n",
    "\n",
    "        top_jobs_str = json.dumps(ranked_jobs[:3], indent=2)\n",
    "\n",
    "        chain_recommendations = prompt_recommendations | llm\n",
    "        res = chain_recommendations.invoke({\n",
    "            \"top_jobs\": top_jobs_str,\n",
    "            \"portfolio_skills\": portfolio_skills\n",
    "        })\n",
    "        json_parser = JsonOutputParser()\n",
    "        return json_parser.parse(res.content)\n",
    "\n",
    "\n",
    "# Main processing functions\n",
    "def process_job_analysis(url, portfolio_csv):\n",
    "    \"\"\"Original job analysis functionality\"\"\"\n",
    "    try:\n",
    "        analyzer = JobAnalyzer()\n",
    "        df = analyzer.load_portfolio(portfolio_csv)\n",
    "        job_data = analyzer.extract_job_posting(url)\n",
    "\n",
    "        job_skills = job_data.get('skills', []) if isinstance(job_data, dict) else job_data[0].get('skills', [])\n",
    "        analysis_result = analyzer.analyze_skills_and_generate_questions(job_skills)\n",
    "\n",
    "        return {\n",
    "            \"job_details\": job_data,\n",
    "            \"skills_analysis\": analysis_result,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "\n",
    "def process_portfolio_tailoring(url, portfolio_csv):\n",
    "    \"\"\"NEW: Portfolio tailoring functionality\"\"\"\n",
    "    try:\n",
    "        analyzer = JobAnalyzer()\n",
    "        df = analyzer.load_portfolio(portfolio_csv)\n",
    "        job_data = analyzer.extract_job_posting(url)\n",
    "\n",
    "        # Get the first job if multiple jobs returned\n",
    "        job_info = job_data if isinstance(job_data, dict) else job_data[0]\n",
    "        tailoring_result = analyzer.tailor_portfolio(df, job_info)\n",
    "\n",
    "        return {\n",
    "            \"tailoring_suggestions\": tailoring_result,\n",
    "            \"job_details\": job_info,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "\n",
    "def process_cover_letter_generation(url, portfolio_csv):\n",
    "    \"\"\"NEW: Cover letter generation functionality\"\"\"\n",
    "    try:\n",
    "        analyzer = JobAnalyzer()\n",
    "        df = analyzer.load_portfolio(portfolio_csv)\n",
    "        job_data = analyzer.extract_job_posting(url)\n",
    "\n",
    "        # Get the first job if multiple jobs returned\n",
    "        job_info = job_data if isinstance(job_data, dict) else job_data[0]\n",
    "        cover_letter_result = analyzer.generate_cover_letter(df, job_info)\n",
    "\n",
    "        return {\n",
    "            \"cover_letter\": cover_letter_result,\n",
    "            \"job_details\": job_info,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "\n",
    "def process_job_search(portfolio_csv, search_terms, location):\n",
    "    \"\"\"NEW: Job search agent functionality\"\"\"\n",
    "    try:\n",
    "        analyzer = JobAnalyzer()\n",
    "        df = analyzer.load_portfolio(portfolio_csv)\n",
    "\n",
    "        # Convert search terms string to list\n",
    "        search_terms_list = [term.strip() for term in search_terms.split(',')] if search_terms else None\n",
    "\n",
    "        job_search_result = analyzer.find_matching_jobs(df, search_terms_list, location)\n",
    "\n",
    "        return {\n",
    "            \"job_search_results\": job_search_result,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "\n",
    "# Gradio Interface\n",
    "def create_gradio_app():\n",
    "    with gr.Blocks(theme='Respair/Shiki@1.2.1', title=\"Enhanced Job Analyzer\") as app:\n",
    "        gr.Markdown(\"# Enhanced Job Analyzer with AI-Powered Features\")\n",
    "        gr.Markdown(\"Upload your portfolio and analyze jobs, tailor your profile, generate cover letters, and find matching opportunities!\")\n",
    "\n",
    "        # Common inputs\n",
    "        with gr.Row():\n",
    "            portfolio_input = gr.File(label=\"Upload Portfolio CSV\", file_types=[\".csv\"])\n",
    "\n",
    "        # Tab interface for different features\n",
    "        with gr.Tabs():\n",
    "            # Tab 1: Original Job Analysis\n",
    "            with gr.TabItem(\"Job Analysis & Interview Questions\"):\n",
    "                with gr.Row():\n",
    "                    url_input1 = gr.Textbox(\n",
    "                        label=\"Job Posting URL\",\n",
    "                        placeholder=\"Enter the URL of the job posting\"\n",
    "                    )\n",
    "\n",
    "                analyze_button = gr.Button(\"Analyze Job Posting\", variant=\"primary\")\n",
    "                analysis_output = gr.JSON(label=\"Analysis Results\")\n",
    "\n",
    "                analyze_button.click(\n",
    "                    process_job_analysis,\n",
    "                    inputs=[url_input1, portfolio_input],\n",
    "                    outputs=analysis_output\n",
    "                )\n",
    "\n",
    "            # Tab 2: Portfolio Tailoring\n",
    "            with gr.TabItem(\"Portfolio Tailoring\"):\n",
    "                with gr.Row():\n",
    "                    url_input2 = gr.Textbox(\n",
    "                        label=\"Job Posting URL\",\n",
    "                        placeholder=\"Enter the URL of the job posting\"\n",
    "                    )\n",
    "\n",
    "                tailor_button = gr.Button(\"Tailor Portfolio\", variant=\"primary\")\n",
    "                tailoring_output = gr.JSON(label=\"Portfolio Tailoring Suggestions\")\n",
    "\n",
    "                tailor_button.click(\n",
    "                    process_portfolio_tailoring,\n",
    "                    inputs=[url_input2, portfolio_input],\n",
    "                    outputs=tailoring_output\n",
    "                )\n",
    "\n",
    "            # Tab 3: Cover Letter Generation\n",
    "            with gr.TabItem(\"Cover Letter Generator\"):\n",
    "                with gr.Row():\n",
    "                    url_input3 = gr.Textbox(\n",
    "                        label=\"Job Posting URL\",\n",
    "                        placeholder=\"Enter the URL of the job posting\"\n",
    "                    )\n",
    "\n",
    "                cover_letter_button = gr.Button(\"Generate Cover Letter\", variant=\"primary\")\n",
    "                cover_letter_output = gr.JSON(label=\"Generated Cover Letter\")\n",
    "\n",
    "                cover_letter_button.click(\n",
    "                    process_cover_letter_generation,\n",
    "                    inputs=[url_input3, portfolio_input],\n",
    "                    outputs=cover_letter_output\n",
    "                )\n",
    "\n",
    "            # Tab 4: Job Search Agent\n",
    "            with gr.TabItem(\"Job Search Agent\"):\n",
    "                with gr.Row():\n",
    "                    search_terms_input = gr.Textbox(\n",
    "                        label=\"Search Terms (comma-separated)\",\n",
    "                        placeholder=\"e.g., Software Engineer, Data Scientist, ML Engineer\",\n",
    "                        value=\"\"\n",
    "                    )\n",
    "                    location_input = gr.Textbox(\n",
    "                        label=\"Location\",\n",
    "                        placeholder=\"e.g., San Francisco, CA\",\n",
    "                        value=\"\"\n",
    "                    )\n",
    "\n",
    "                search_button = gr.Button(\"Search Jobs\", variant=\"primary\")\n",
    "                search_output = gr.JSON(label=\"Job Search Results\")\n",
    "\n",
    "                search_button.click(\n",
    "                    process_job_search,\n",
    "                    inputs=[portfolio_input, search_terms_input, location_input],\n",
    "                    outputs=search_output\n",
    "                )\n",
    "\n",
    "        # Instructions\n",
    "        with gr.Accordion(\"Instructions\", open=False):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### How to Use This Enhanced Job Analyzer:\n",
    "            \n",
    "            1. **Upload Portfolio CSV**: Your CSV should have a 'Technology' column with comma-separated skills\n",
    "            2. **Job Analysis**: Paste job URL to get skills match and interview questions\n",
    "            3. **Portfolio Tailoring**: Get suggestions to improve your portfolio for specific jobs\n",
    "            4. **Cover Letter**: Generate personalized cover letters based on your portfolio and job requirements\n",
    "            5. **Job Search**: Find jobs that match your portfolio skills automatically\n",
    "            \n",
    "            ### Features:\n",
    "            - Skills matching and gap analysis\n",
    "            - AI-generated interview questions  \n",
    "            - Portfolio optimization suggestions\n",
    "            - Personalized cover letter generation\n",
    "            - Intelligent job search and ranking\n",
    "            - Career development recommendations\n",
    "            \"\"\")\n",
    "\n",
    "    return app\n",
    "\n",
    "\n",
    "# Launch the application\n",
    "if __name__ == \"__main__\":\n",
    "    app = create_gradio_app()\n",
    "    app.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
